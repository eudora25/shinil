#!/usr/bin/env python3
"""
Supabase ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸
ëª¨ë“  í…Œì´ë¸”ì„ CSV íŒŒì¼ë¡œ ë°±ì—…í•©ë‹ˆë‹¤.
"""

import os
import sys
import csv
import json
from datetime import datetime
from supabase import create_client, Client
import pandas as pd

# Supabase ì„¤ì •
SUPABASE_URL = "https://selklngerzfmuvagcvvf.supabase.co"
SUPABASE_ANON_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNlbGtsbmdlcnpmbXV2YWdjdnZmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTI3MzQ5MDUsImV4cCI6MjA2ODMxMDkwNX0.cRe78UqA-HDdVClq0qrXlOXxwNpQWLB6ycFnoHzQI4U"

def create_supabase_client() -> Client:
    """Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
        print("âœ… Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì„±ê³µ")
        return supabase
    except Exception as e:
        print(f"âŒ Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        sys.exit(1)

def get_all_tables(supabase: Client) -> list:
    """ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # PostgreSQL ì‹œìŠ¤í…œ í…Œì´ë¸”ì—ì„œ ì‚¬ìš©ì í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        query = """
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_type = 'BASE TABLE'
        ORDER BY table_name;
        """
        
        # RPCë¥¼ í†µí•´ ì¿¼ë¦¬ ì‹¤í–‰
        result = supabase.rpc('exec_sql', {'sql_query': query}).execute()
        
        if hasattr(result, 'data') and result.data:
            tables = [row['table_name'] for row in result.data]
        else:
            # RPCê°€ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²½ìš° ê¸°ë³¸ í…Œì´ë¸” ëª©ë¡ ì‚¬ìš©
            tables = [
                'users',
                'companies',
                'products',
                'clients',
                'pharmacies',
                'wholesale_sales',
                'direct_sales',
                'performance_records',
                'settlement_months',
                'absorption_analysis',
                'notices',
                'commission_grades',
                'review_records'
            ]
        
        print(f"ğŸ“‹ ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ")
        for table in tables:
            print(f"  - {table}")
        
        return tables
    except Exception as e:
        print(f"âš ï¸ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ í…Œì´ë¸” ëª©ë¡ ì‚¬ìš©: {e}")
        # ê¸°ë³¸ í…Œì´ë¸” ëª©ë¡ ë°˜í™˜
        return [
            'users',
            'companies',
            'products',
            'clients',
            'pharmacies',
            'wholesale_sales',
            'direct_sales',
            'performance_records',
            'settlement_months',
            'absorption_analysis',
            'notices',
            'commission_grades',
            'review_records'
        ]

def backup_table_to_csv(supabase: Client, table_name: str, backup_dir: str) -> bool:
    """ë‹¨ì¼ í…Œì´ë¸”ì„ CSVë¡œ ë°±ì—…"""
    try:
        print(f"ğŸ“Š {table_name} í…Œì´ë¸” ë°±ì—… ì¤‘...")
        
        # í…Œì´ë¸” ë°ì´í„° ì¡°íšŒ
        response = supabase.table(table_name).select('*').execute()
        
        if not response.data:
            print(f"  âš ï¸ {table_name} í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return True
        
        # CSV íŒŒì¼ ê²½ë¡œ
        csv_file_path = os.path.join(backup_dir, f"{table_name}.csv")
        
        # ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
        with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:
            if response.data:
                fieldnames = response.data[0].keys()
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(response.data)
        
        print(f"  âœ… {table_name} ë°±ì—… ì™„ë£Œ ({len(response.data)}ê°œ í–‰)")
        return True
        
    except Exception as e:
        print(f"  âŒ {table_name} ë°±ì—… ì‹¤íŒ¨: {e}")
        return False

def create_backup_directory() -> str:
    """ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir = f"database_backup_{timestamp}"
    
    if not os.path.exists(backup_dir):
        os.makedirs(backup_dir)
        print(f"ğŸ“ ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±: {backup_dir}")
    
    return backup_dir

def create_backup_summary(backup_dir: str, tables: list, success_count: int, total_count: int):
    """ë°±ì—… ìš”ì•½ ì •ë³´ ìƒì„±"""
    summary = {
        "backup_timestamp": datetime.now().isoformat(),
        "total_tables": total_count,
        "successful_backups": success_count,
        "failed_backups": total_count - success_count,
        "backup_directory": backup_dir,
        "tables": tables
    }
    
    summary_file = os.path.join(backup_dir, "backup_summary.json")
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“‹ ë°±ì—… ìš”ì•½ ì €ì¥: {summary_file}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Supabase ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹œì‘")
    print("=" * 50)
    
    # Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    supabase = create_supabase_client()
    
    # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
    backup_dir = create_backup_directory()
    
    # í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    tables = get_all_tables(supabase)
    
    if not tables:
        print("âŒ ë°±ì—…í•  í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“¦ ì´ {len(tables)}ê°œ í…Œì´ë¸” ë°±ì—… ì‹œì‘")
    print("=" * 50)
    
    # ê° í…Œì´ë¸” ë°±ì—…
    success_count = 0
    for table in tables:
        if backup_table_to_csv(supabase, table, backup_dir):
            success_count += 1
    
    # ë°±ì—… ìš”ì•½ ìƒì„±
    create_backup_summary(backup_dir, tables, success_count, len(tables))
    
    print("\n" + "=" * 50)
    print(f"ğŸ‰ ë°±ì—… ì™„ë£Œ!")
    print(f"ğŸ“ ë°±ì—… ìœ„ì¹˜: {backup_dir}")
    print(f"âœ… ì„±ê³µ: {success_count}/{len(tables)} í…Œì´ë¸”")
    print(f"âŒ ì‹¤íŒ¨: {len(tables) - success_count}/{len(tables)} í…Œì´ë¸”")

if __name__ == "__main__":
    main() 