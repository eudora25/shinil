// Vercel ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ í˜•ì‹ìœ¼ë¡œ ë³€ê²½ (19_ì‹¤ì ì¦ë¹™íŒŒì¼.xlsx í˜•ì‹ì— ë§ì¶¤)
import { createClient } from '@supabase/supabase-js'

import { config } from 'dotenv'
import path from 'path'
import { fileURLToPath } from 'url'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
const nodeEnv = process.env.NODE_ENV || 'development'
const envFile = nodeEnv === 'production' ? '.env.production' : '.env.local'

try {
  config({ 
    path: path.join(__dirname, '..', envFile),
    override: true
  })
  console.log(`âœ… í™˜ê²½ íŒŒì¼ ë¡œë“œ ì„±ê³µ: ${envFile}`)
} catch (error) {
  console.log(`âš ï¸ í™˜ê²½ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: ${envFile} - ëŸ°íƒ€ì„ í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©`)
}

export default async function handler(req, res) {
  try {
    if (req.method !== 'GET') {
      return res.status(405).json({
        success: false,
        message: 'Method not allowed'
      })
    }

    // í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (ê°œí–‰ ë¬¸ì ì œê±°)
    const supabaseUrl = (process.env.VITE_SUPABASE_URL || process.env.SUPABASE_URL)?.trim()
    const supabaseAnonKey = (process.env.VITE_SUPABASE_ANON_KEY || process.env.SUPABASE_ANON_KEY)?.trim()
    const serviceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY?.trim()

    // í™˜ê²½ ë³€ìˆ˜ ë””ë²„ê¹…
    console.log('Performance Evidence Files API - Environment variables:', {
      supabaseUrl: supabaseUrl ? 'Set' : 'Missing',
      supabaseAnonKey: supabaseAnonKey ? 'Set' : 'Missing',
      serviceRoleKey: serviceRoleKey ? 'Set' : 'Missing'
    })

    // í™˜ê²½ ë³€ìˆ˜ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (ê°œë°œìš©)
    if (!supabaseUrl || !supabaseAnonKey) {
      return res.status(500).json({
        success: false,
        message: 'Server configuration error',
        error: 'Supabase configuration missing'
      })
    }

    // Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± (RLS ì •ì±… ë¬´ì‹œë¥¼ ìœ„í•´ Service Role Key ì‚¬ìš©)
    let supabase
    if (serviceRoleKey) {
      console.log('ğŸ” Using Service Role Key for RLS bypass')
      supabase = createClient(supabaseUrl, serviceRoleKey)
    } else {
      console.log('ğŸ” Service Role Key not available, using Anon Key')
      supabase = createClient(supabaseUrl, supabaseAnonKey)
    }

    // ì—°ê²° í…ŒìŠ¤íŠ¸ (ê°„ë‹¨í•œ ì¿¼ë¦¬)
    const { data: testData, error: testError } = await supabase
      .from('performance_evidence_files')
      .select('id')
      .limit(1)

    if (testError) {
      console.error('Supabase connection test failed:', testError)
      return res.status(500).json({
        success: false,
        message: 'Supabase connection failed',
        error: testError.message,
        debug: {
          supabaseUrl: supabaseUrl ? 'Set' : 'Missing',
          supabaseAnonKey: supabaseAnonKey ? 'Set' : 'Missing',
          testError: testError
        }
      })
    }

    // í† í° ê²€ì¦
    const authHeader = req.headers.authorization
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return res.status(401).json({
        success: false,
        message: 'Unauthorized'
      })
    }

    const token = authHeader.substring(7)
    const { data: { user }, error: authError } = await supabase.auth.getUser(token)

    if (authError || !user) {
      return res.status(401).json({
        success: false,
        message: 'Unauthorized'
      })
    }

    // ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° íŒŒì‹± (19_ì‹¤ì ì¦ë¹™íŒŒì¼.xlsx í˜•ì‹ì— ë§ì¶¤)
    const { 
      page = 1, 
      limit = 100, 
      startDate, 
      endDate
    } = req.query

    // í˜ì´ì§€ë„¤ì´ì…˜ ê³„ì‚°
    const pageNum = parseInt(page, 10)
    const limitNum = parseInt(limit, 10)
    const offset = (pageNum - 1) * limitNum

    // ì…ë ¥ê°’ ê²€ì¦
    if (pageNum < 1 || limitNum < 1 || limitNum > 1000) {
      return res.status(400).json({
        success: false,
        message: 'Invalid pagination parameters. Page must be >= 1, limit must be between 1 and 1000.'
      })
    }

    // ê¸°ë³¸ ì¿¼ë¦¬ ì„¤ì •
    let query = supabase
      .from('performance_evidence_files')
      .select('*', { count: 'exact' })
      .order('uploaded_at', { ascending: false })

    // ë‚ ì§œ í•„í„°ë§ (startDate, endDate íŒŒë¼ë¯¸í„° ì§€ì›)
    if (startDate) {
      query = query.gte('uploaded_at', startDate)
    }
    if (endDate) {
      query = query.lte('uploaded_at', endDate)
    }

    // í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
    query = query.range(offset, offset + limitNum - 1)

    // ë°ì´í„° ì¡°íšŒ
    const { data: files, error: filesError, count } = await query

    console.log('ğŸ” Performance Evidence Files query result:', { data: files?.length, error: filesError, count })

    if (filesError) {
      console.error('Performance Evidence Files fetch error:', filesError)
      return res.status(500).json({
        success: false,
        message: 'Failed to fetch performance evidence files',
        error: filesError.message
      })
    }

    // í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ê³„ì‚°
    const totalPages = Math.ceil(count / limitNum)
    const hasNextPage = pageNum < totalPages
    const hasPrevPage = pageNum > 1

    // 19_ì‹¤ì ì¦ë¹™íŒŒì¼.xlsx í˜•ì‹ì— ë§ì¶˜ ì‘ë‹µ
    const response = {
      success: true,
      message: 'ì‹¤ì  ì¦ë¹™ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì„±ê³µ',
      data: files || [],
      count: count || 0,
      page: pageNum,
      limit: limitNum,
      totalPages,
      hasNextPage,
      hasPrevPage
    }

    res.json(response)

  } catch (error) {
    console.error('Performance Evidence Files API error details:', {
      message: error.message,
      stack: error.stack,
      timestamp: new Date().toISOString()
    })

    return res.status(500).json({
      success: false,
      message: 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
      error: error.message,
      timestamp: new Date().toISOString()
    })
  }
}