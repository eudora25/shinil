#!/usr/bin/env python3
"""
ì‹ ì¼ì œì•½ ì‹¤ì ê´€ë¦¬í”„ë¡œê·¸ë¨ - ì „ì²´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
ì›ê²© Supabaseì—ì„œ ë¡œì»¬ PostgreSQLë¡œ ëª¨ë“  ë°ì´í„°ë¥¼ ì´ì „í•©ë‹ˆë‹¤.
"""

import psycopg2
import requests
import json
import os
from datetime import datetime
import time

# ì›ê²© Supabase ì„¤ì •
SUPABASE_URL = "https://selklngerzfmuvagcvvf.supabase.co"
SUPABASE_ANON_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNlbGtsbmdlcnpmbXV2YWdjdnZmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTI3MzQ5MDUsImV4cCI6MjA2ODMxMDkwNX0.cRe78UqA-HDdVClq0qrXlOXxwNpQWLB6ycFnoHzQI4U"

# ë¡œì»¬ PostgreSQL ì„¤ì •
LOCAL_DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'shinil_pms',
    'user': 'postgres',
    'password': 'postgres'
}

# ë§ˆì´ê·¸ë ˆì´ì…˜í•  í…Œì´ë¸” ëª©ë¡ (ìš°ì„ ìˆœìœ„ ìˆœì„œ)
TABLES = [
    # ê¸°ë³¸ ë§ˆìŠ¤í„° ë°ì´í„°
    'companies',
    'products', 
    'clients',
    'pharmacies',
    'settlement_months',
    
    # ê±°ë˜ ë°ì´í„°
    'wholesale_sales',
    'direct_sales',
    
    # ì‹¤ì  ë°ì´í„°
    'performance_records',
    'absorption_analysis',
    
    # ì‹œìŠ¤í…œ ë°ì´í„°
    'notices',
    'users',
    'profiles'
]

def get_supabase_data(table_name, limit=None):
    """Supabaseì—ì„œ í…Œì´ë¸” ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = f"{SUPABASE_URL}/rest/v1/{table_name}"
    headers = {
        'apikey': SUPABASE_ANON_KEY,
        'Authorization': f'Bearer {SUPABASE_ANON_KEY}',
        'Content-Type': 'application/json'
    }
    
    params = {}
    if limit:
        params['limit'] = limit
    
    try:
        print(f"ğŸ“¡ {table_name} í…Œì´ë¸” ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        data = response.json()
        print(f"âœ… {table_name}: {len(data)}ê°œ ë ˆì½”ë“œ ê°€ì ¸ì˜´")
        return data
    except requests.exceptions.RequestException as e:
        print(f"âŒ {table_name} í…Œì´ë¸” ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None

def create_table_schema(conn, table_name, data):
    """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not data or len(data) == 0:
        print(f"âš ï¸ {table_name} í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ì–´ ìŠ¤í‚¤ë§ˆ ìƒì„± ê±´ë„ˆëœ€")
        return False
    
    try:
        cursor = conn.cursor()
        
        # ì²« ë²ˆì§¸ ë ˆì½”ë“œì—ì„œ ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ
        first_record = data[0]
        columns = []
        column_definitions = []
        
        for column_name, value in first_record.items():
            columns.append(column_name)
            
            # ë°ì´í„° íƒ€ì… ì¶”ì •
            if value is None:
                column_definitions.append(f"{column_name} TEXT")
            elif isinstance(value, bool):
                column_definitions.append(f"{column_name} BOOLEAN")
            elif isinstance(value, int):
                column_definitions.append(f"{column_name} INTEGER")
            elif isinstance(value, float):
                column_definitions.append(f"{column_name} NUMERIC")
            elif isinstance(value, str):
                # ë‚ ì§œ/ì‹œê°„ í˜•ì‹ í™•ì¸
                if 'T' in value and ('Z' in value or '+' in value):
                    column_definitions.append(f"{column_name} TIMESTAMP")
                else:
                    column_definitions.append(f"{column_name} TEXT")
            else:
                column_definitions.append(f"{column_name} TEXT")
        
        # í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        cursor.execute("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = %s
            );
        """, (table_name,))
        
        if cursor.fetchone()[0]:
            print(f"â„¹ï¸ {table_name} í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤")
            return True
        
        # í…Œì´ë¸” ìƒì„±
        create_sql = f"""
        CREATE TABLE {table_name} (
            {', '.join(column_definitions)}
        );
        """
        
        cursor.execute(create_sql)
        conn.commit()
        print(f"âœ… {table_name} í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ {table_name} í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
        conn.rollback()
        return False

def insert_data(conn, table_name, data):
    """ë°ì´í„°ë¥¼ í…Œì´ë¸”ì— ì‚½ì…í•©ë‹ˆë‹¤."""
    if not data or len(data) == 0:
        print(f"âš ï¸ {table_name} í…Œì´ë¸”ì— ì‚½ì…í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    try:
        cursor = conn.cursor()
        
        # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜)
        cursor.execute(f"DELETE FROM {table_name}")
        print(f"ğŸ—‘ï¸ {table_name} ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        
        # ì»¬ëŸ¼ëª… ì¶”ì¶œ
        columns = list(data[0].keys())
        placeholders = ', '.join(['%s'] * len(columns))
        column_names = ', '.join(columns)
        
        # ë°°ì¹˜ ì‚½ì…
        batch_size = 1000
        total_inserted = 0
        
        for i in range(0, len(data), batch_size):
            batch = data[i:i + batch_size]
            values_list = []
            
            for record in batch:
                values = []
                for column in columns:
                    value = record.get(column)
                    # None ê°’ì„ NULLë¡œ ì²˜ë¦¬
                    if value is None:
                        values.append(None)
                    else:
                        values.append(value)
                values_list.append(tuple(values))
            
            insert_sql = f"""
            INSERT INTO {table_name} ({column_names})
            VALUES ({placeholders})
            """
            
            cursor.executemany(insert_sql, values_list)
            total_inserted += len(batch)
            
            if len(data) > batch_size:
                print(f"ğŸ“Š {table_name}: {total_inserted}/{len(data)} ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ")
        
        conn.commit()
        print(f"âœ… {table_name}: ì´ {total_inserted}ê°œ ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ {table_name} ë°ì´í„° ì‚½ì… ì‹¤íŒ¨: {e}")
        conn.rollback()
        return False

def get_table_info(conn, table_name):
    """í…Œì´ë¸” ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        cursor = conn.cursor()
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        count = cursor.fetchone()[0]
        
        cursor.execute(f"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = '{table_name}' ORDER BY ordinal_position")
        columns = cursor.fetchall()
        
        return {
            'count': count,
            'columns': [{'name': col[0], 'type': col[1]} for col in columns]
        }
    except Exception as e:
        print(f"âŒ {table_name} í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def main():
    """ë©”ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ í•¨ìˆ˜"""
    print("ğŸš€ ì‹ ì¼ì œì•½ ì‹¤ì ê´€ë¦¬í”„ë¡œê·¸ë¨ - ì „ì²´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸŒ ì›ê²© Supabase: {SUPABASE_URL}")
    print(f"ğŸ—„ï¸ ë¡œì»¬ PostgreSQL: {LOCAL_DB_CONFIG['host']}:{LOCAL_DB_CONFIG['port']}/{LOCAL_DB_CONFIG['database']}")
    print("=" * 60)
    
    # ë¡œì»¬ PostgreSQL ì—°ê²°
    try:
        conn = psycopg2.connect(**LOCAL_DB_CONFIG)
        print("âœ… ë¡œì»¬ PostgreSQL ì—°ê²° ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ë¡œì»¬ PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
        return
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ í†µê³„
    migration_stats = {
        'total_tables': len(TABLES),
        'successful_tables': 0,
        'failed_tables': 0,
        'total_records': 0,
        'start_time': datetime.now()
    }
    
    # ê° í…Œì´ë¸” ì²˜ë¦¬
    for i, table_name in enumerate(TABLES, 1):
        print(f"\nğŸ“‹ [{i}/{len(TABLES)}] {table_name} í…Œì´ë¸” ì²˜ë¦¬ ì¤‘...")
        print("-" * 40)
        
        # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        data = get_supabase_data(table_name)
        if data is None:
            print(f"âš ï¸ {table_name} í…Œì´ë¸” ê±´ë„ˆëœ€")
            migration_stats['failed_tables'] += 1
            continue
        
        if len(data) == 0:
            print(f"âš ï¸ {table_name} í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            migration_stats['successful_tables'] += 1
            continue
        
        # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ìƒì„±
        if not create_table_schema(conn, table_name, data):
            print(f"âŒ {table_name} í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨")
            migration_stats['failed_tables'] += 1
            continue
        
        # ë°ì´í„° ì‚½ì…
        if insert_data(conn, table_name, data):
            migration_stats['successful_tables'] += 1
            migration_stats['total_records'] += len(data)
            
            # í…Œì´ë¸” ì •ë³´ ì¶œë ¥
            table_info = get_table_info(conn, table_name)
            if table_info:
                print(f"ğŸ“Š {table_name} í…Œì´ë¸” ì •ë³´:")
                print(f"   - ë ˆì½”ë“œ ìˆ˜: {table_info['count']:,}ê°œ")
                print(f"   - ì»¬ëŸ¼ ìˆ˜: {len(table_info['columns'])}ê°œ")
        else:
            migration_stats['failed_tables'] += 1
        
        # ì§„í–‰ë¥  í‘œì‹œ
        progress = (i / len(TABLES)) * 100
        print(f"ğŸ“ˆ ì§„í–‰ë¥ : {progress:.1f}% ({i}/{len(TABLES)})")
        
        # ì ì‹œ ëŒ€ê¸° (API í˜¸ì¶œ ì œí•œ ë°©ì§€)
        if i < len(TABLES):
            time.sleep(1)
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
    conn.close()
    end_time = datetime.now()
    duration = end_time - migration_stats['start_time']
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“… ì™„ë£Œ ì‹œê°„: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"â±ï¸ ì†Œìš” ì‹œê°„: {duration}")
    print(f"ğŸ“Š ì „ì²´ í…Œì´ë¸”: {migration_stats['total_tables']}ê°œ")
    print(f"âœ… ì„±ê³µ: {migration_stats['successful_tables']}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {migration_stats['failed_tables']}ê°œ")
    print(f"ğŸ“ ì´ ë ˆì½”ë“œ: {migration_stats['total_records']:,}ê°œ")
    print("=" * 60)
    
    # ìµœì¢… í…Œì´ë¸” ëª©ë¡ ì¶œë ¥
    print("\nğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ëœ í…Œì´ë¸” ëª©ë¡:")
    try:
        conn = psycopg2.connect(**LOCAL_DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT table_name, 
                   (SELECT COUNT(*) FROM information_schema.columns WHERE table_name = t.table_name) as column_count
            FROM information_schema.tables t
            WHERE table_schema = 'public'
            AND table_type = 'BASE TABLE'
            ORDER BY table_name
        """)
        
        tables = cursor.fetchall()
        for table_name, column_count in tables:
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            record_count = cursor.fetchone()[0]
            print(f"   - {table_name}: {record_count:,}ê°œ ë ˆì½”ë“œ, {column_count}ê°œ ì»¬ëŸ¼")
        
        conn.close()
    except Exception as e:
        print(f"âŒ í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    print("\nğŸ”— ë‹¤ìŒ ë‹¨ê³„:")
    print("1. pgAdminì—ì„œ ë°ì´í„° í™•ì¸: http://localhost:5050")
    print("2. API í…ŒìŠ¤íŠ¸: http://localhost:3000/test")
    print("3. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸: http://localhost:3001/api/test")

if __name__ == "__main__":
    main() 